{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from src.datasets.dataset import VOCDataset\n",
    "\n",
    "# Model\n",
    "from src.models.yolo import YoloV1\n",
    "from src.core.config import YoloConfig\n",
    "import torch.optim as optim\n",
    "from src.models.loss import YoloLoss\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import cv2\n",
    "\n",
    "import gc\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO config\n",
    "config = YoloConfig()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Dataset\n",
    "scale = 1.1\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=int(config.image_size * scale)),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(config.image_size * scale),\n",
    "            min_width=int(config.image_size * scale),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.RandomCrop(width=config.image_size, height=config.image_size),\n",
    "        A.ColorJitter(brightness=0.6, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.ShiftScaleRotate(\n",
    "                    rotate_limit=20, p=0.5, border_mode=cv2.BORDER_CONSTANT\n",
    "                ),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Blur(p=0.1),\n",
    "        A.CLAHE(p=0.1),\n",
    "        A.Posterize(p=0.1),\n",
    "        A.ToGray(p=0.1),\n",
    "        A.ChannelShuffle(p=0.05),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[],),\n",
    ")\n",
    "\n",
    "val_test_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=config.image_size),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=config.image_size, min_width=config.image_size, border_mode=cv2.BORDER_CONSTANT\n",
    "        ),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255,),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", min_visibility=0.4, label_fields=[]),\n",
    ")\n",
    "\n",
    "train_images_path = \"/home/adriano/Documents/datasets/VOCFULL/old_txt_files/train.txt\"\n",
    "val_images_path = \"/home/adriano/Documents/datasets/VOCFULL/old_txt_files/test.txt\"\n",
    "\n",
    "num_worker = 4 * int(torch.cuda.device_count())\n",
    "batch_size = 1\n",
    "\n",
    "train_dataset = VOCDataset(train_images_path, transform=train_transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, drop_last=True, num_workers=num_worker, pin_memory=True)\n",
    "\n",
    "val_dataset = VOCDataset(val_images_path, transform=val_test_transforms)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, drop_last=True, num_workers=num_worker, pin_memory=True)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Model\n",
    "model = YoloV1()\n",
    "model.to(device=device)\n",
    "\n",
    "criterion = YoloLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=config.lr, epochs = config.epochs, steps_per_epoch = 2*(len(train_dataloader)), \n",
    "                        pct_start=0.3, div_factor=100, anneal_strategy='cos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - training\n",
    "from src.core.helpers import cellboxes_to_boxes, mAp, non_max_suppression\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for _ , (image, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        predictions = model(image)\n",
    "        loss = criterion(predictions, labels)\n",
    "        total_loss += loss.item()               \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # adjust learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluating(model, dataloader, criterion, device):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_pred_boxes = []\n",
    "    all_true_boxes = []\n",
    "    train_idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, total=len(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_preds = model(inputs)\n",
    "\n",
    "            batch_size = inputs.shape[0]\n",
    "            true_bboxes = cellboxes_to_boxes(labels)\n",
    "            bboxes = cellboxes_to_boxes(y_preds)\n",
    "\n",
    "            for idx in range(batch_size):\n",
    "                nms_boxes = non_max_suppression(\n",
    "                    bboxes[idx],\n",
    "                    iou_threshold=config.iou_threshold,\n",
    "                    threshold=config.threshold,\n",
    "                    box_format=config.box_format,\n",
    "                )\n",
    "                for nms_box in nms_boxes:\n",
    "                    all_pred_boxes.append([train_idx] + nms_box)\n",
    "\n",
    "                for box in true_bboxes[idx]:\n",
    "                    # many will get converted to 0 pred\n",
    "                    if box[1] > config.threshold:\n",
    "                        all_true_boxes.append([train_idx] + box)\n",
    "\n",
    "            train_idx += 1\n",
    "\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(y_preds, labels)\n",
    "            total_loss += loss.item()\n",
    "           \n",
    "\n",
    "    metric_object = mAp(all_pred_boxes, all_true_boxes,box_format=\"midpoint\")\n",
    "\n",
    "    evaluation_loss = total_loss / len(dataloader)\n",
    "    evaluation_metric = metric_object\n",
    "    return evaluation_loss, evaluation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        print(\"\\nEpoch {}\".format(1 + epoch))\n",
    "        \n",
    "        train_mean_loss = train(train_loader=train_dataloader,\n",
    "                model=model,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer, device=device)\n",
    "        \n",
    "        print(\"Train mean loss: {}\".format(train_mean_loss))\n",
    "        \n",
    "        evaluation_loss, evaluation_metric = evaluating(model=model, dataloader=val_dataloader, criterion=criterion, device=device)\n",
    "        print(\"Val mean loss: {} mAp: {}\".format(evaluation_loss, evaluation_metric))\n",
    " \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
